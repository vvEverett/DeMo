{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48b22ef3",
   "metadata": {},
   "source": [
    "# EGO Vehicle Trajectory Clustering\n",
    "\n",
    "Extract features from the last 6 seconds of EGO vehicle trajectories from the first 100 train files and perform clustering analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9012977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "project_root = Path.cwd().resolve()\n",
    "if not (project_root / \"src\").exists():\n",
    "    for parent in project_root.parents:\n",
    "        if (parent / \"src\").exists():\n",
    "            project_root = parent\n",
    "            break\n",
    "\n",
    "if (project_root / \"src\").exists() and str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from src.utils.data_visualization import get_available_files, DataLoader\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "print(\"âœ… Libraries loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3b2ebf",
   "metadata": {},
   "source": [
    "## 1. Load data and extract EGO features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c46adbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_PATH = Path('/data1/xiaowei/code/DeMo/data/DeMo_processed')\n",
    "N_FILES = 1000 # 199908 for all training files\n",
    "TOTAL_TIMESTEPS = 110  # 11 seconds * 10 Hz\n",
    "HISTORY_TIMESTEPS = 50  # First 5 seconds\n",
    "FUTURE_TIMESTEPS = 60   # Last 6 seconds\n",
    "\n",
    "# Get files\n",
    "train_files = get_available_files(DATA_PATH, 'train')[:N_FILES]\n",
    "print(f\"ðŸ“‚ Loaded {len(train_files)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42935595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_trajectory(positions, velocity, angles):\n",
    "    \"\"\"\n",
    "    Normalize trajectory: start at origin, end aligned to y-axis\n",
    "    \n",
    "    Args:\n",
    "        positions: numpy array of shape (60, 2) - [x, y] positions\n",
    "        velocity: numpy array of shape (60,) - velocity values\n",
    "        angles: numpy array of shape (60,) - heading angles\n",
    "    \n",
    "    Returns:\n",
    "        features: numpy array of shape (60, 4) - [normalized_x, normalized_y, velocity, angle]\n",
    "    \"\"\"\n",
    "    # 1. Translation: Move start to origin\n",
    "    start_pos = positions[0]\n",
    "    end_pos = positions[-1]\n",
    "    positions_normalized = positions - start_pos  # (60, 2)\n",
    "    \n",
    "    # 2. Rotation alignment: Align start->end vector to positive y-axis direction\n",
    "    # Calculate vector from start to end\n",
    "    start_to_end = end_pos - start_pos\n",
    "    target_angle = np.arctan2(start_to_end[1], start_to_end[0])  # Current angle\n",
    "    \n",
    "    # Calculate rotation angle (rotate vector to positive y-axis, i.e., 90 degrees)\n",
    "    rotation_angle = np.pi / 2 - target_angle\n",
    "    \n",
    "    # Construct rotation matrix\n",
    "    cos_theta = np.cos(rotation_angle)\n",
    "    sin_theta = np.sin(rotation_angle)\n",
    "    rotation_matrix = np.array([\n",
    "        [cos_theta, -sin_theta],\n",
    "        [sin_theta, cos_theta]\n",
    "    ])\n",
    "    \n",
    "    # Apply rotation to positions\n",
    "    positions_aligned = positions_normalized @ rotation_matrix.T  # (60, 2)\n",
    "    \n",
    "    # Apply rotation to angles (adjust all angles by rotation_angle)\n",
    "    angles_aligned = angles - rotation_angle\n",
    "    \n",
    "    # 3. Feature combination: [normalized x, y, velocity, angle]\n",
    "    features = np.column_stack([\n",
    "        positions_aligned[:, 0],  # aligned x (lateral offset)\n",
    "        positions_aligned[:, 1],  # aligned y (longitudinal progress)\n",
    "        velocity,                 # original velocity\n",
    "        angles_aligned            # aligned heading angles\n",
    "    ])  # (60, 4)\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "def extract_ego_features(file_path):\n",
    "    \"\"\"\n",
    "    Extract features from the last 6 seconds of EGO vehicle trajectory using DataLoader\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the data file\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (features, agent_type_combined) where:\n",
    "            - features: numpy array of shape (60, 4) or None if invalid\n",
    "            - agent_type_combined: string indicating agent type ('Vehicle', 'Pedestrian', 'Cyclist', 'Other')\n",
    "    \"\"\"\n",
    "    # Use DataLoader to load and extract ego data\n",
    "    loader = DataLoader()\n",
    "    data = loader.load_scenario(file_path)\n",
    "    \n",
    "    if data is None:\n",
    "        return None, None\n",
    "    \n",
    "    # Get focal agent index\n",
    "    focal_idx = loader.current_metadata['focal_agent_idx']\n",
    "    \n",
    "    # Use plot_ego_velocity_analysis to get comprehensive ego data\n",
    "    # This includes positions, velocities, angles, and accelerations\n",
    "    from src.utils.data_visualization import plot_ego_velocity_analysis\n",
    "    \n",
    "    analysis_data = plot_ego_velocity_analysis(loader, show_acceleration=False, time_window=None)\n",
    "    \n",
    "    if analysis_data is None:\n",
    "        return None, None\n",
    "    \n",
    "    # Extract agent_type_combined\n",
    "    agent_type_combined = analysis_data['agent_type_combined']\n",
    "    \n",
    "    # Get full trajectory data\n",
    "    positions_full = analysis_data['positions']\n",
    "    velocities_full = analysis_data['velocities']\n",
    "    angles_full = analysis_data['angles']\n",
    "    timesteps_full = analysis_data['timesteps']\n",
    "    \n",
    "    # Filter for future timesteps (timestep 50-110, i.e., last 6 seconds)\n",
    "    future_mask = timesteps_full >= HISTORY_TIMESTEPS\n",
    "    \n",
    "    if not future_mask.any():\n",
    "        return None, None\n",
    "    \n",
    "    positions = positions_full[future_mask]\n",
    "    velocity = velocities_full[future_mask]\n",
    "    angles = angles_full[future_mask]\n",
    "    \n",
    "    # Check if we have exactly 60 timesteps\n",
    "    if len(positions) != FUTURE_TIMESTEPS:\n",
    "        return None, None\n",
    "    \n",
    "    # Normalize trajectory with positions, velocity, and angles from DataLoader\n",
    "    features = normalize_trajectory(positions, velocity, angles)\n",
    "    \n",
    "    return features, agent_type_combined\n",
    "\n",
    "\n",
    "# Extract all features and agent types\n",
    "all_features = []\n",
    "all_agent_types = []\n",
    "valid_files = []\n",
    "\n",
    "print(\"Extracting features using DataLoader with plot_ego_velocity_analysis...\")\n",
    "print(\"ðŸ’¡ This provides comprehensive data: positions, velocities, angles from the data loader\")\n",
    "for i, file_path in enumerate(train_files):\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print(f\"  Processing {i + 1}/{len(train_files)}...\")\n",
    "    \n",
    "    features, agent_type = extract_ego_features(file_path)\n",
    "    if features is not None:\n",
    "        all_features.append(features)\n",
    "        all_agent_types.append(agent_type)\n",
    "        valid_files.append(file_path.name)\n",
    "\n",
    "print(f\"\\nâœ… Successfully extracted features from {len(all_features)} scenarios\")\n",
    "print(f\"Feature dimensions: {all_features[0].shape}\")\n",
    "print(f\"ðŸ’¡ Features include: [normalized_x, normalized_y, velocity, angle]\")\n",
    "print(f\"ðŸ’¡ All data sourced from DataLoader's get_agent_trajectory method\")\n",
    "\n",
    "# Show agent type distribution\n",
    "from collections import Counter\n",
    "agent_type_counts = Counter(all_agent_types)\n",
    "print(f\"\\nðŸ“Š Agent Type Distribution:\")\n",
    "for agent_type, count in sorted(agent_type_counts.items()):\n",
    "    print(f\"  {agent_type}: {count} ({count/len(all_agent_types)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb284b71",
   "metadata": {},
   "source": [
    "## 2. Pure Heuristic-Based Classification into 5 Expert Categories\n",
    "\n",
    "Classify all trajectories using heuristic rules into 5 expert categories:\n",
    "- **Expert 1**: Lane Keeping (Including Straight Ahead/Lane Change)\n",
    "- **Expert 2**: Turn Left (Including Turn from stop/Turn from moving state)\n",
    "- **Expert 3**: Turn Right (Including Turn from stop/Turn from moving state)\n",
    "- **Expert 4**: Constraint-Driven Deceleration (Including Stop/Yield/Junction/Congestion)\n",
    "- **Expert 5**: Others (Long-tail and infrequent behaviors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ce7dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_trajectories_to_5_experts(features, agent_types):\n",
    "    \"\"\"\n",
    "    Classify trajectories into 5 expert categories using heuristic rules:\n",
    "    \n",
    "    Expert 1: Lane Keeping (Including Straight Ahead/Lane Change)\n",
    "    Expert 2: Turn Left (Including Turn from stop/Turn from moving state)\n",
    "    Expert 3: Turn Right (Including Turn from stop/Turn from moving state)\n",
    "    Expert 4: Constraint-Driven Deceleration (Including Stop/Yield/Junction/Congestion)\n",
    "    Expert 5: Others (Long-tail and infrequent behaviors)\n",
    "    \n",
    "    Args:\n",
    "        features: array of shape (n_samples, 60, 4) containing [x, y, velocity, angle]\n",
    "        agent_types: list of agent_type_combined strings\n",
    "    \n",
    "    Returns:\n",
    "        labels: array of shape (n_samples,) with values 1-5 representing expert categories\n",
    "        label_names: dict mapping label to expert name\n",
    "    \"\"\"\n",
    "    n_samples = len(features)\n",
    "    labels = np.full(n_samples, 5, dtype=int)  # Default: Expert 5 (Others)\n",
    "    \n",
    "    # ===== Thresholds for classification =====\n",
    "    WINDOW_SIZE = 5  # Number of timesteps to average for initial/final speed\n",
    "    \n",
    "    # Expert 4: Constraint-Driven Deceleration thresholds\n",
    "    DECEL_FINAL_SPEED_THRESHOLD = 3.0  # m/s, final speed low or near stop\n",
    "    DECEL_SPEED_DECREASE_THRESHOLD = -2.5  # m/s, significant speed decrease\n",
    "    \n",
    "    # Expert 1: Lane Keeping thresholds\n",
    "    LANE_KEEPING_SPEED_STD_THRESHOLD = 2.0  # m/s, relatively stable speed\n",
    "    LANE_KEEPING_ANGLE_STD_THRESHOLD = 0.2  # rad, low heading change (~11 degrees)\n",
    "    LANE_KEEPING_LATERAL_THRESHOLD = 3.0  # m, small lateral deviation\n",
    "    LANE_KEEPING_MIN_SPEED = 3.0  # m/s, minimum average speed\n",
    "    \n",
    "    # Expert 2 & 3: Turn detection thresholds\n",
    "    TURN_ANGLE_CHANGE_THRESHOLD = 0.35  # rad, significant heading change (~20 degrees)\n",
    "    TURN_TOTAL_ANGLE_THRESHOLD = 0.5  # rad, total angle change (~28 degrees)\n",
    "    \n",
    "    for i, sample in enumerate(features):\n",
    "        agent_type = agent_types[i]\n",
    "        \n",
    "        # Non-vehicle agents go to Expert 5 (Others)\n",
    "        if agent_type in ['Pedestrian']: # ['Pedestrian', 'Cyclist']\n",
    "            labels[i] = 5  # Expert 5: Others\n",
    "            continue\n",
    "        \n",
    "        # Extract features for vehicles\n",
    "        velocities = sample[:, 2]\n",
    "        angles = sample[:, 3]\n",
    "        x_positions = sample[:, 0]\n",
    "        y_positions = sample[:, 1]\n",
    "        \n",
    "        # Calculate statistics\n",
    "        initial_speed = np.mean(velocities[:WINDOW_SIZE])\n",
    "        final_speed = np.mean(velocities[-WINDOW_SIZE:])\n",
    "        speed_change = final_speed - initial_speed\n",
    "        avg_speed = np.mean(velocities)\n",
    "        speed_std = np.std(velocities)\n",
    "        angle_std = np.std(angles)\n",
    "        lateral_deviation = np.std(x_positions)\n",
    "        \n",
    "        # Calculate total angle change (accumulated heading change)\n",
    "        angle_diffs = np.diff(angles)\n",
    "        # Normalize angle differences to [-pi, pi]\n",
    "        angle_diffs = np.arctan2(np.sin(angle_diffs), np.cos(angle_diffs))\n",
    "        total_angle_change = np.sum(angle_diffs)\n",
    "        abs_total_angle_change = np.abs(total_angle_change)\n",
    "        \n",
    "        # Calculate final direction (last position relative to start)\n",
    "        final_x = x_positions[-1] - x_positions[0]\n",
    "        final_y = y_positions[-1] - y_positions[0]\n",
    "        \n",
    "        # ===== Classification Rules (priority order) =====\n",
    "        \n",
    "        # Rule 1: Expert 4 - Constraint-Driven Deceleration\n",
    "        # Significant deceleration with low final speed\n",
    "        if (final_speed < DECEL_FINAL_SPEED_THRESHOLD and \n",
    "            speed_change < DECEL_SPEED_DECREASE_THRESHOLD):\n",
    "            labels[i] = 4  # Expert 4: Constraint-Driven Deceleration\n",
    "        \n",
    "        # Rule 2: Expert 2 - Turn Left\n",
    "        # Significant angle change + net left turn (positive angle change in normalized coordinates)\n",
    "        elif (abs_total_angle_change > TURN_TOTAL_ANGLE_THRESHOLD and \n",
    "              total_angle_change > TURN_ANGLE_CHANGE_THRESHOLD):\n",
    "            labels[i] = 2  # Expert 2: Turn Left\n",
    "        \n",
    "        # Rule 3: Expert 3 - Turn Right\n",
    "        # Significant angle change + net right turn (negative angle change)\n",
    "        elif (abs_total_angle_change > TURN_TOTAL_ANGLE_THRESHOLD and \n",
    "              total_angle_change < -TURN_ANGLE_CHANGE_THRESHOLD):\n",
    "            labels[i] = 3  # Expert 3: Turn Right\n",
    "        \n",
    "        # Rule 4: Expert 1 - Lane Keeping\n",
    "        # Stable speed, stable heading, small lateral deviation, reasonable speed\n",
    "        elif (speed_std < LANE_KEEPING_SPEED_STD_THRESHOLD and \n",
    "              angle_std < LANE_KEEPING_ANGLE_STD_THRESHOLD and\n",
    "              lateral_deviation < LANE_KEEPING_LATERAL_THRESHOLD and\n",
    "              avg_speed > LANE_KEEPING_MIN_SPEED):\n",
    "            labels[i] = 1  # Expert 1: Lane Keeping\n",
    "        \n",
    "        # Rule 5: Expert 5 - Others (default, already set)\n",
    "        # Includes: complex maneuvers, lane changes with acceleration, unusual patterns\n",
    "    \n",
    "    # Define label names\n",
    "    label_names = {\n",
    "        1: \"Expert 1: Lane Keeping\",\n",
    "        2: \"Expert 2: Turn Left\",\n",
    "        3: \"Expert 3: Turn Right\",\n",
    "        4: \"Expert 4: Constraint-Driven Deceleration\",\n",
    "        5: \"Expert 5: Others\"\n",
    "    }\n",
    "    \n",
    "    return labels, label_names\n",
    "\n",
    "\n",
    "# Apply the 5-expert classification\n",
    "expert_labels, expert_names = classify_trajectories_to_5_experts(all_features, all_agent_types)\n",
    "\n",
    "# Count samples in each category\n",
    "print(\"=\" * 70)\n",
    "print(\"ðŸŽ¯ Pure Heuristic-Based Classification into 5 Expert Categories:\")\n",
    "print(\"=\" * 70)\n",
    "for expert_id in range(1, 6):\n",
    "    count = np.sum(expert_labels == expert_id)\n",
    "    percentage = count / len(all_features) * 100\n",
    "    print(f\"  {expert_names[expert_id]:<45s}: {count:4d} ({percentage:5.1f}%)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nâœ… Total classified samples: {len(expert_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c32bfe",
   "metadata": {},
   "source": [
    "## 3. Visualize 5-Expert Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5d97b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Expert distribution statistics\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Get expert counts\n",
    "unique_labels = sorted(np.unique(expert_labels))\n",
    "label_names_list = []\n",
    "expert_counts_list = []\n",
    "\n",
    "# Define colors for 5 experts\n",
    "expert_colors = {\n",
    "    1: '#4ECDC4',  # Teal for Lane Keeping\n",
    "    2: '#FFB84D',  # Orange for Turn Left\n",
    "    3: '#FF6B6B',  # Red for Turn Right\n",
    "    4: '#9B59B6',  # Purple for Constraint-Driven Deceleration\n",
    "    5: '#95A5A6'   # Gray for Others\n",
    "}\n",
    "\n",
    "for label in unique_labels:\n",
    "    count = np.sum(expert_labels == label)\n",
    "    expert_counts_list.append(count)\n",
    "    label_names_list.append(expert_names[label])\n",
    "\n",
    "# Plot expert distribution bar chart\n",
    "colors_bar = [expert_colors[label] for label in unique_labels]\n",
    "axes[0].bar(range(len(expert_counts_list)), expert_counts_list, color=colors_bar, alpha=0.7)\n",
    "axes[0].set_xticks(range(len(expert_counts_list)))\n",
    "axes[0].set_xticklabels([f'Expert {i}' for i in unique_labels], rotation=0, ha='center')\n",
    "axes[0].set_xlabel('Expert Category', fontsize=12)\n",
    "axes[0].set_ylabel('Sample Count', fontsize=12)\n",
    "axes[0].set_title('Sample Distribution Across 5 Expert Categories', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot expert distribution pie chart\n",
    "axes[1].pie(expert_counts_list, labels=[f'Expert {i}' for i in unique_labels],\n",
    "            autopct='%1.1f%%', colors=colors_bar, startangle=90)\n",
    "axes[1].set_title('Expert Sample Proportions', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nðŸ“Š Expert Distribution Details:\")\n",
    "for label, name, count in zip(unique_labels, label_names_list, expert_counts_list):\n",
    "    print(f\"  {name:<50s}: {count:4d} ({count/len(expert_labels)*100:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa420ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Typical trajectory visualization for each expert\n",
    "unique_labels = sorted(np.unique(expert_labels))\n",
    "n_experts = len(unique_labels)\n",
    "\n",
    "# Create layout for experts\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Define colors for 5 experts\n",
    "expert_colors = {\n",
    "    1: '#4ECDC4',  # Teal for Lane Keeping\n",
    "    2: '#FFB84D',  # Orange for Turn Left\n",
    "    3: '#FF6B6B',  # Red for Turn Right\n",
    "    4: '#9B59B6',  # Purple for Constraint-Driven Deceleration\n",
    "    5: '#95A5A6'   # Gray for Others\n",
    "}\n",
    "\n",
    "# Get expert counts\n",
    "expert_counts = {label: np.sum(expert_labels == label) for label in unique_labels}\n",
    "\n",
    "for idx, expert_id in enumerate(unique_labels):\n",
    "    # Get all samples for this expert\n",
    "    expert_mask = expert_labels == expert_id\n",
    "    expert_samples = [all_features[i] for i in range(len(all_features)) if expert_mask[i]]\n",
    "    \n",
    "    # Plot all trajectories for this expert (relative to start position)\n",
    "    ax = axes[idx]\n",
    "    for sample in expert_samples:\n",
    "        # Convert to relative positions\n",
    "        x_rel = sample[:, 0] - sample[0, 0]\n",
    "        y_rel = sample[:, 1] - sample[0, 1]\n",
    "        ax.plot(x_rel, y_rel, alpha=0.3, linewidth=1, color=expert_colors[expert_id])\n",
    "    \n",
    "    # Calculate and plot average trajectory (relative)\n",
    "    mean_sample = np.mean(expert_samples, axis=0)\n",
    "    mean_x_rel = mean_sample[:, 0] - mean_sample[0, 0]\n",
    "    mean_y_rel = mean_sample[:, 1] - mean_sample[0, 1]\n",
    "    ax.plot(mean_x_rel, mean_y_rel, color='darkblue', linewidth=3, label='Average Trajectory')\n",
    "    \n",
    "    ax.scatter(0, 0, color='green', s=100, marker='o', label='Start Point', zorder=5)\n",
    "    ax.scatter(mean_x_rel[-1], mean_y_rel[-1], color='red', s=100, marker='*', label='End Point', zorder=5)\n",
    "    \n",
    "    # Set background color\n",
    "    ax.set_facecolor(expert_colors[expert_id] + '20')  # 20 is alpha in hex\n",
    "    \n",
    "    ax.set_xlabel('Relative X Position (m)', fontsize=10)\n",
    "    ax.set_ylabel('Relative Y Position (m)', fontsize=10)\n",
    "    ax.set_title(f'{expert_names[expert_id]}\\n({expert_counts[expert_id]} samples)', \n",
    "                 fontsize=12, fontweight='bold')\n",
    "    ax.legend(loc='best', fontsize=8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.axis('equal')\n",
    "\n",
    "# Hide unused subplot\n",
    "if n_experts < 6:\n",
    "    axes[5].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a2fcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Load and verify the saved CSV\n",
    "loaded_df = pd.read_csv(csv_path_latest)\n",
    "print(f\"âœ… Loaded CSV with {len(loaded_df)} rows\")\n",
    "print(f\"\\nColumn types:\")\n",
    "print(loaded_df.dtypes)\n",
    "print(f\"\\nSummary statistics:\")\n",
    "print(loaded_df.describe())\n",
    "\n",
    "# Verify expert distribution matches\n",
    "print(f\"\\nâœ… Verification: Expert distribution\")\n",
    "for expert_id in range(1, 6):\n",
    "    count_original = np.sum(expert_labels == expert_id)\n",
    "    count_csv = len(loaded_df[loaded_df['expert_id'] == expert_id])\n",
    "    match_status = \"âœ“\" if count_original == count_csv else \"âœ—\"\n",
    "    print(f\"  {match_status} Expert {expert_id}: Original={count_original}, CSV={count_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a522cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Speed pattern visualization for each expert\n",
    "unique_labels = sorted(np.unique(expert_labels))\n",
    "n_experts = len(unique_labels)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Define colors for 5 experts\n",
    "expert_colors = {\n",
    "    1: '#4ECDC4',  # Teal for Lane Keeping\n",
    "    2: '#FFB84D',  # Orange for Turn Left\n",
    "    3: '#FF6B6B',  # Red for Turn Right\n",
    "    4: '#9B59B6',  # Purple for Constraint-Driven Deceleration\n",
    "    5: '#95A5A6'   # Gray for Others\n",
    "}\n",
    "\n",
    "expert_counts = {label: np.sum(expert_labels == label) for label in unique_labels}\n",
    "\n",
    "for idx, expert_id in enumerate(unique_labels):\n",
    "    expert_mask = expert_labels == expert_id\n",
    "    expert_samples = [all_features[i] for i in range(len(all_features)) if expert_mask[i]]\n",
    "    \n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Plot velocity for all samples\n",
    "    for sample in expert_samples:\n",
    "        vel = sample[:, 2]\n",
    "        ax.plot(vel, alpha=0.2, linewidth=1, color=expert_colors[expert_id])\n",
    "    \n",
    "    # Plot average velocity\n",
    "    mean_vel = np.mean([s[:, 2] for s in expert_samples], axis=0)\n",
    "    ax.plot(mean_vel, color='darkblue', linewidth=2.5, label='Average Speed')\n",
    "    \n",
    "    ax.axhline(y=0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "    \n",
    "    # Set background color\n",
    "    ax.set_facecolor(expert_colors[expert_id] + '20')\n",
    "    \n",
    "    ax.set_xlabel('Time Step', fontsize=10)\n",
    "    ax.set_ylabel('Velocity (m/s)', fontsize=10)\n",
    "    ax.set_title(f'{expert_names[expert_id]} - Speed Pattern', fontsize=12, fontweight='bold')\n",
    "    ax.legend(loc='best', fontsize=8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Hide unused subplot\n",
    "if n_experts < 6:\n",
    "    axes[5].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2e35aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Load and verify the saved CSV\n",
    "loaded_df = pd.read_csv(csv_path_latest)\n",
    "print(f\"âœ… Loaded CSV with {len(loaded_df)} rows\")\n",
    "print(f\"\\nColumn types:\")\n",
    "print(loaded_df.dtypes)\n",
    "print(f\"\\nSummary statistics:\")\n",
    "print(loaded_df.describe())\n",
    "\n",
    "# Verify expert distribution matches\n",
    "print(f\"\\nâœ… Verification: Expert distribution\")\n",
    "for expert_id in range(1, 6):\n",
    "    count_original = np.sum(expert_labels == expert_id)\n",
    "    count_csv = len(loaded_df[loaded_df['expert_id'] == expert_id])\n",
    "    match_status = \"âœ“\" if count_original == count_csv else \"âœ—\"\n",
    "    print(f\"  {match_status} Expert {expert_id}: Original={count_original}, CSV={count_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a85d661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Expert feature statistics comparison\n",
    "unique_labels = sorted(np.unique(expert_labels))\n",
    "expert_stats = []\n",
    "\n",
    "for expert_id in unique_labels:\n",
    "    expert_mask = expert_labels == expert_id\n",
    "    expert_samples = [all_features[i] for i in range(len(all_features)) if expert_mask[i]]\n",
    "    \n",
    "    # Calculate statistics\n",
    "    all_samples_array = np.array(expert_samples)  # (n_samples, 60, 4)\n",
    "    \n",
    "    stats = {\n",
    "        'expert': expert_names[expert_id],\n",
    "        'label': expert_id,\n",
    "        'count': len(expert_samples),\n",
    "        'avg_x_displacement': np.mean([s[-1, 0] - s[0, 0] for s in expert_samples]),  # Final - initial X\n",
    "        'avg_y_displacement': np.mean([s[-1, 1] - s[0, 1] for s in expert_samples]),  # Final - initial Y\n",
    "        'avg_total_displacement': np.mean([np.sqrt((s[-1, 0] - s[0, 0])**2 + (s[-1, 1] - s[0, 1])**2) for s in expert_samples]),\n",
    "        'avg_speed_change': np.mean([np.sum(np.diff(s[:, 2])) for s in expert_samples]),  # Total speed change\n",
    "        'speed_volatility': np.mean([np.std(s[:, 2]) for s in expert_samples])\n",
    "    }\n",
    "    expert_stats.append(stats)\n",
    "\n",
    "# Convert to DataFrame and display\n",
    "import pandas as pd\n",
    "stats_df = pd.DataFrame(expert_stats)\n",
    "stats_df = stats_df.round(3)\n",
    "\n",
    "print(\"\\nðŸ“ˆ Statistical Feature Comparison Across 5 Expert Categories:\\n\")\n",
    "print(stats_df[['expert', 'count', 'avg_x_displacement', 'avg_y_displacement', \n",
    "                'avg_total_displacement', 'avg_speed_change', 'speed_volatility']].to_string(index=False))\n",
    "\n",
    "# Visualize statistical features\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "# Define colors for 5 experts\n",
    "expert_colors = {\n",
    "    1: '#4ECDC4',  # Teal for Lane Keeping\n",
    "    2: '#FFB84D',  # Orange for Turn Left\n",
    "    3: '#FF6B6B',  # Red for Turn Right\n",
    "    4: '#9B59B6',  # Purple for Constraint-Driven Deceleration\n",
    "    5: '#95A5A6'   # Gray for Others\n",
    "}\n",
    "\n",
    "bar_colors = [expert_colors[label] for label in stats_df['label']]\n",
    "\n",
    "# Average X Displacement\n",
    "axes[0, 0].bar(range(len(stats_df)), stats_df['avg_x_displacement'], color=bar_colors)\n",
    "axes[0, 0].set_xticks(range(len(stats_df)))\n",
    "axes[0, 0].set_xticklabels([f'Expert {i}' for i in stats_df['label']], rotation=0, ha='center', fontsize=9)\n",
    "axes[0, 0].set_ylabel('Average X Displacement (m)')\n",
    "axes[0, 0].set_title('Average X Displacement Comparison')\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Average Y Displacement\n",
    "axes[0, 1].bar(range(len(stats_df)), stats_df['avg_y_displacement'], color=bar_colors)\n",
    "axes[0, 1].set_xticks(range(len(stats_df)))\n",
    "axes[0, 1].set_xticklabels([f'Expert {i}' for i in stats_df['label']], rotation=0, ha='center', fontsize=9)\n",
    "axes[0, 1].set_ylabel('Average Y Displacement (m)')\n",
    "axes[0, 1].set_title('Average Y Displacement Comparison')\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Total Displacement\n",
    "axes[0, 2].bar(range(len(stats_df)), stats_df['avg_total_displacement'], color=bar_colors)\n",
    "axes[0, 2].set_xticks(range(len(stats_df)))\n",
    "axes[0, 2].set_xticklabels([f'Expert {i}' for i in stats_df['label']], rotation=0, ha='center', fontsize=9)\n",
    "axes[0, 2].set_ylabel('Average Total Displacement (m)')\n",
    "axes[0, 2].set_title('Total Displacement Comparison')\n",
    "axes[0, 2].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Speed Change\n",
    "axes[0, 3].bar(range(len(stats_df)), stats_df['avg_speed_change'], color=bar_colors)\n",
    "axes[0, 3].set_xticks(range(len(stats_df)))\n",
    "axes[0, 3].set_xticklabels([f'Expert {i}' for i in stats_df['label']], rotation=0, ha='center', fontsize=9)\n",
    "axes[0, 3].set_ylabel('Average Speed Change (m/s)')\n",
    "axes[0, 3].set_title('Average Speed Change Comparison')\n",
    "axes[0, 3].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Speed Volatility\n",
    "axes[1, 0].bar(range(len(stats_df)), stats_df['speed_volatility'], color=bar_colors)\n",
    "axes[1, 0].set_xticks(range(len(stats_df)))\n",
    "axes[1, 0].set_xticklabels([f'Expert {i}' for i in stats_df['label']], rotation=0, ha='center', fontsize=9)\n",
    "axes[1, 0].set_ylabel('Speed Volatility (m/s)')\n",
    "axes[1, 0].set_title('Speed Volatility Comparison')\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Average Speed\n",
    "avg_speed = [np.mean([s[:, 2] for s in expert_samples]) for expert_samples in \n",
    "             [[all_features[i] for i in range(len(all_features)) if expert_labels[i] == label] \n",
    "              for label in unique_labels]]\n",
    "axes[1, 1].bar(range(len(stats_df)), avg_speed, color=bar_colors)\n",
    "axes[1, 1].set_xticks(range(len(stats_df)))\n",
    "axes[1, 1].set_xticklabels([f'Expert {i}' for i in stats_df['label']], rotation=0, ha='center', fontsize=9)\n",
    "axes[1, 1].set_ylabel('Average Speed (m/s)')\n",
    "axes[1, 1].set_title('Average Speed Comparison')\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Max Speed\n",
    "max_speed = [np.max([np.max(s[:, 2]) for s in expert_samples]) for expert_samples in \n",
    "             [[all_features[i] for i in range(len(all_features)) if expert_labels[i] == label] \n",
    "              for label in unique_labels]]\n",
    "axes[1, 2].bar(range(len(stats_df)), max_speed, color=bar_colors)\n",
    "axes[1, 2].set_xticks(range(len(stats_df)))\n",
    "axes[1, 2].set_xticklabels([f'Expert {i}' for i in stats_df['label']], rotation=0, ha='center', fontsize=9)\n",
    "axes[1, 2].set_ylabel('Max Speed (m/s)')\n",
    "axes[1, 2].set_title('Max Speed Comparison')\n",
    "axes[1, 2].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Angle Volatility\n",
    "angle_volatility = [np.mean([np.std(s[:, 3]) for s in expert_samples]) for expert_samples in \n",
    "                    [[all_features[i] for i in range(len(all_features)) if expert_labels[i] == label] \n",
    "                     for label in unique_labels]]\n",
    "axes[1, 3].bar(range(len(stats_df)), angle_volatility, color=bar_colors)\n",
    "axes[1, 3].set_xticks(range(len(stats_df)))\n",
    "axes[1, 3].set_xticklabels([f'Expert {i}' for i in stats_df['label']], rotation=0, ha='center', fontsize=9)\n",
    "axes[1, 3].set_ylabel('Angle Volatility (rad)')\n",
    "axes[1, 3].set_title('Angle Volatility Comparison')\n",
    "axes[1, 3].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d06e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Use t-SNE for dimensionality reduction visualization\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Flatten time series data for t-SNE\n",
    "X_flat = np.array([feat.flatten() for feat in all_features])\n",
    "\n",
    "# t-SNE reduce to 2D\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "X_tsne = tsne.fit_transform(X_flat)\n",
    "\n",
    "# Visualization with different colors for all categories\n",
    "unique_labels = sorted(np.unique(expert_labels))\n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "\n",
    "# Define colors for 5 experts\n",
    "expert_colors = {\n",
    "    1: '#4ECDC4',  # Teal for Lane Keeping\n",
    "    2: '#FFB84D',  # Orange for Turn Left\n",
    "    3: '#FF6B6B',  # Red for Turn Right\n",
    "    4: '#9B59B6',  # Purple for Constraint-Driven Deceleration\n",
    "    5: '#95A5A6'   # Gray for Others\n",
    "}\n",
    "\n",
    "# Create color map\n",
    "color_map = [expert_colors[label] for label in expert_labels]\n",
    "\n",
    "scatter = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=color_map, \n",
    "                      s=100, alpha=0.7, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "# Add expert center annotations\n",
    "for expert_id in unique_labels:\n",
    "    expert_mask = expert_labels == expert_id\n",
    "    expert_center = X_tsne[expert_mask].mean(axis=0)\n",
    "    \n",
    "    marker_color = expert_colors[expert_id]\n",
    "    label_text = f'E{expert_id}'\n",
    "    \n",
    "    plt.scatter(expert_center[0], expert_center[1], \n",
    "                marker='X', s=500, c=marker_color, edgecolors='black', linewidth=2)\n",
    "    plt.text(expert_center[0], expert_center[1], label_text, \n",
    "             fontsize=12, fontweight='bold', ha='center', va='center',\n",
    "             bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "\n",
    "# Create custom legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor=expert_colors[1], edgecolor='black', label='Expert 1: Lane Keeping'),\n",
    "    Patch(facecolor=expert_colors[2], edgecolor='black', label='Expert 2: Turn Left'),\n",
    "    Patch(facecolor=expert_colors[3], edgecolor='black', label='Expert 3: Turn Right'),\n",
    "    Patch(facecolor=expert_colors[4], edgecolor='black', label='Expert 4: Deceleration'),\n",
    "    Patch(facecolor=expert_colors[5], edgecolor='black', label='Expert 5: Others')\n",
    "]\n",
    "plt.legend(handles=legend_elements, loc='best', fontsize=11)\n",
    "\n",
    "plt.xlabel('t-SNE Dimension 1', fontsize=12)\n",
    "plt.ylabel('t-SNE Dimension 2', fontsize=12)\n",
    "plt.title('Trajectory Feature t-SNE Visualization\\n(Pure Heuristic-Based 5-Expert Classification)', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… t-SNE visualization completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60b648f",
   "metadata": {},
   "source": [
    "## Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aad96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Create DataFrame with classification results\n",
    "classification_results = []\n",
    "for i, (filename, expert_id) in enumerate(zip(valid_files, expert_labels)):\n",
    "    classification_results.append({\n",
    "        'file_index': i,\n",
    "        'filename': filename,\n",
    "        'expert_id': int(expert_id)\n",
    "        # 'expert_name': expert_names[expert_id],\n",
    "        # 'agent_type': all_agent_types[i]\n",
    "    })\n",
    "\n",
    "df_classifications = pd.DataFrame(classification_results)\n",
    "\n",
    "# Save to CSV\n",
    "output_dir = Path('/data1/xiaowei/code/DeMo/data/DeMo_classified')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Generate timestamped filename\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "csv_filename = f'heuristic_classifications_{timestamp}.csv'\n",
    "csv_path = output_dir / csv_filename\n",
    "\n",
    "# Also save a latest version (no timestamp)\n",
    "csv_path_latest = output_dir / 'heuristic_classifications_latest.csv'\n",
    "\n",
    "# Save both versions\n",
    "df_classifications.to_csv(csv_path, index=False)\n",
    "df_classifications.to_csv(csv_path_latest, index=False)\n",
    "\n",
    "print(f\"âœ… Classification results saved to:\")\n",
    "print(f\"   ðŸ“„ {csv_path}\")\n",
    "print(f\"   ðŸ“„ {csv_path_latest}\")\n",
    "print(f\"\\nðŸ“Š Saved {len(df_classifications)} classified scenarios\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(df_classifications.head())\n",
    "print(f\"\\nCSV columns: {list(df_classifications.columns)}\")\n",
    "print(f\"\\nExpert distribution in saved CSV:\")\n",
    "print(df_classifications['expert_id'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d437dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Load and verify the saved CSV\n",
    "loaded_df = pd.read_csv(csv_path_latest)\n",
    "print(f\"âœ… Loaded CSV with {len(loaded_df)} rows\")\n",
    "print(f\"\\nColumn types:\")\n",
    "print(loaded_df.dtypes)\n",
    "print(f\"\\nSummary statistics:\")\n",
    "print(loaded_df.describe())\n",
    "\n",
    "# Verify expert distribution matches\n",
    "print(f\"\\nâœ… Verification: Expert distribution\")\n",
    "for expert_id in range(1, 6):\n",
    "    count_original = np.sum(expert_labels == expert_id)\n",
    "    count_csv = len(loaded_df[loaded_df['expert_id'] == expert_id])\n",
    "    match_status = \"âœ“\" if count_original == count_csv else \"âœ—\"\n",
    "    print(f\"  {match_status} Expert {expert_id}: Original={count_original}, CSV={count_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeMo_XW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
