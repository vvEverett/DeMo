{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48b22ef3",
   "metadata": {},
   "source": [
    "# EGO Vehicle Trajectory Endpoint Clustering\n",
    "\n",
    "Extract normalized trajectory endpoints from the last 6 seconds of EGO vehicle trajectories and perform clustering analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9012977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "project_root = Path.cwd().resolve()\n",
    "if not (project_root / \"src\").exists():\n",
    "    for parent in project_root.parents:\n",
    "        if (parent / \"src\").exists():\n",
    "            project_root = parent\n",
    "            break\n",
    "\n",
    "if (project_root / \"src\").exists() and str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from src.utils.data_visualization import get_available_files, DataLoader\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "print(\"âœ… Libraries loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3b2ebf",
   "metadata": {},
   "source": [
    "## 1. Load data and extract EGO features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c46adbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_PATH = Path('/data1/xiaowei/code/DeMo/data/DeMo_processed')\n",
    "N_FILES = 1000\n",
    "TOTAL_TIMESTEPS = 110  # 11 seconds * 10 Hz\n",
    "HISTORY_TIMESTEPS = 50  # First 5 seconds\n",
    "FUTURE_TIMESTEPS = 60   # Last 6 seconds\n",
    "\n",
    "# Get files\n",
    "train_files = get_available_files(DATA_PATH, 'train')[:N_FILES]\n",
    "print(f\"ðŸ“‚ Loaded {len(train_files)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42935595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_trajectory(positions, heading_angle):\n",
    "    \"\"\"\n",
    "    Normalize trajectory: place the 5s position at the origin and align heading to +Y.\n",
    "\n",
    "    Args:\n",
    "        positions: numpy array of shape (60, 2) - [x, y] positions\n",
    "        heading_angle: float heading (radians) at the normalization timestamp\n",
    "\n",
    "    Returns:\n",
    "        numpy array of shape (60, 2) with normalized coordinates\n",
    "    \"\"\"\n",
    "    # Translation: move 5s position to origin\n",
    "    start_pos = positions[0]\n",
    "    positions_translated = positions - start_pos\n",
    "\n",
    "    # Convert to radians if the dataset stores angles in degrees\n",
    "    if np.abs(heading_angle) > np.pi:\n",
    "        heading_angle = np.deg2rad(heading_angle)\n",
    "\n",
    "    # Align heading to positive Y axis\n",
    "    rotation_angle = np.pi / 2 - heading_angle\n",
    "    cos_theta = np.cos(rotation_angle)\n",
    "    sin_theta = np.sin(rotation_angle)\n",
    "    rotation_matrix = np.array([\n",
    "        [cos_theta, -sin_theta],\n",
    "        [sin_theta, cos_theta]\n",
    "    ])\n",
    "\n",
    "    positions_aligned = positions_translated @ rotation_matrix.T\n",
    "    return positions_aligned\n",
    "\n",
    "\n",
    "def extract_ego_trajectory(file_path):\n",
    "    \"\"\"\n",
    "    Extract normalized full trajectory from the last 6 seconds of EGO vehicle\n",
    "\n",
    "    Args:\n",
    "        file_path: Path to the data file\n",
    "\n",
    "    Returns:\n",
    "        trajectory: numpy array of shape (60, 2) - [normalized_x, normalized_y] or None if invalid\n",
    "    \"\"\"\n",
    "    # Use DataLoader to load and extract ego data\n",
    "    loader = DataLoader()\n",
    "    data = loader.load_scenario(file_path)\n",
    "\n",
    "    if data is None:\n",
    "        return None\n",
    "\n",
    "    # Get focal agent index\n",
    "    focal_idx = loader.current_metadata['focal_agent_idx']\n",
    "\n",
    "    # Use plot_ego_velocity_analysis to get comprehensive ego data\n",
    "    from src.utils.data_visualization import plot_ego_velocity_analysis\n",
    "\n",
    "    analysis_data = plot_ego_velocity_analysis(loader, show_acceleration=False, time_window=None)\n",
    "\n",
    "    if analysis_data is None:\n",
    "        return None\n",
    "\n",
    "    # Get full trajectory data\n",
    "    positions_full = analysis_data['positions']\n",
    "    timesteps_full = analysis_data['timesteps']\n",
    "    angles_full = analysis_data['angles']\n",
    "\n",
    "    # Filter for future timesteps (timestep 50-110, i.e., last 6 seconds)\n",
    "    future_mask = timesteps_full >= HISTORY_TIMESTEPS\n",
    "\n",
    "    if not future_mask.any():\n",
    "        return None\n",
    "\n",
    "    positions = positions_full[future_mask]\n",
    "    angles = angles_full[future_mask]\n",
    "\n",
    "    # Check if we have exactly 60 timesteps\n",
    "    if len(positions) != FUTURE_TIMESTEPS or len(angles) != FUTURE_TIMESTEPS:\n",
    "        return None\n",
    "\n",
    "    heading_start = float(angles[0])\n",
    "\n",
    "    # Normalize trajectory and return full trajectory\n",
    "    trajectory = normalize_trajectory(positions, heading_start)\n",
    "\n",
    "    return trajectory\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5981986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all trajectories (we'll save full trajectories for faster visualization)\n",
    "all_trajectories = []\n",
    "valid_files = []\n",
    "\n",
    "print(\"Extracting normalized trajectories...\")\n",
    "for i, file_path in enumerate(train_files):\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print(f\"  Processing {i + 1}/{len(train_files)}...\")\n",
    "    \n",
    "    trajectory = extract_ego_trajectory(file_path)\n",
    "    if trajectory is not None:\n",
    "        all_trajectories.append(trajectory)\n",
    "        valid_files.append(file_path.name)\n",
    "\n",
    "# Convert to numpy array\n",
    "all_trajectories = np.array(all_trajectories)  # Shape: (n_samples, 60, 2)\n",
    "\n",
    "# Extract endpoints for clustering\n",
    "all_endpoints = all_trajectories[:, -1, :]  # Shape: (n_samples, 2)\n",
    "\n",
    "print(f\"\\nâœ… Successfully extracted {len(all_trajectories)} trajectories\")\n",
    "print(f\"Trajectory dimensions: {all_trajectories.shape}\")\n",
    "print(f\"Endpoint dimensions: {all_endpoints.shape}\")\n",
    "print(f\"ðŸ’¡ Clustering will be based on endpoints: [normalized_x, normalized_y]\")\n",
    "print(f\"ðŸ’¡ Normalization: 5s position at origin (0,0), 5s heading aligned to +Y axis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ce7dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means clustering on trajectory endpoints\n",
    "N_CLUSTERS = 6\n",
    "\n",
    "# Standardize the endpoints\n",
    "scaler = StandardScaler()\n",
    "endpoints_scaled = scaler.fit_transform(all_endpoints)\n",
    "\n",
    "# Apply K-Means clustering\n",
    "kmeans = KMeans(n_clusters=N_CLUSTERS, random_state=42, n_init=10)\n",
    "cluster_labels = kmeans.fit_predict(endpoints_scaled)\n",
    "\n",
    "print(f\"âœ… K-Means clustering completed with {N_CLUSTERS} clusters\")\n",
    "print(f\"\\nðŸ“Š Cluster Distribution:\")\n",
    "for i in range(N_CLUSTERS):\n",
    "    count = np.sum(cluster_labels == i)\n",
    "    print(f\"  Cluster {i}: {count} samples ({count/len(cluster_labels)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c32bfe",
   "metadata": {},
   "source": [
    "## 2. Visualize endpoint clustering results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5d97b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Endpoint scatter plot with cluster colors\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Downsample for faster rendering if needed\n",
    "MAX_POINTS = 4000\n",
    "rng = np.random.default_rng(42)\n",
    "if len(all_endpoints) > MAX_POINTS:\n",
    "    sample_idx = rng.choice(len(all_endpoints), size=MAX_POINTS, replace=False)\n",
    "    endpoints_plot = all_endpoints[sample_idx]\n",
    "    labels_plot = cluster_labels[sample_idx]\n",
    "else:\n",
    "    endpoints_plot = all_endpoints\n",
    "    labels_plot = cluster_labels\n",
    "\n",
    "colors = plt.cm.tab10(labels_plot)\n",
    "plt.scatter(endpoints_plot[:, 0], endpoints_plot[:, 1],\n",
    "            c=colors, s=36, alpha=0.6, linewidth=0)\n",
    "\n",
    "cluster_centers_original = scaler.inverse_transform(kmeans.cluster_centers_)\n",
    "for i, center in enumerate(cluster_centers_original):\n",
    "    plt.scatter(center[0], center[1],\n",
    "                marker='X', s=400, c=[plt.cm.tab10(i)],\n",
    "                edgecolors='black', linewidth=1.5, zorder=10)\n",
    "    plt.text(center[0], center[1], f'C{i}',\n",
    "             fontsize=14, fontweight='bold', ha='center', va='center',\n",
    "             bbox=dict(boxstyle='round,pad=0.4', facecolor='white', alpha=0.9))\n",
    "\n",
    "plt.scatter(0, 0, marker='o', s=200, c='green',\n",
    "            edgecolors='black', linewidth=1.5, zorder=10, label='Start (Origin)')\n",
    "\n",
    "plt.xlabel('Normalized X Position (m)', fontsize=14)\n",
    "plt.ylabel('Normalized Y Position (m)', fontsize=14)\n",
    "plt.title('Trajectory Endpoint Clustering (Normalized to Origin)', fontsize=16, fontweight='bold')\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "if len(endpoints_plot) < len(all_endpoints):\n",
    "    print(f\"\\nShowing {len(endpoints_plot)} of {len(all_endpoints)} endpoints (random sample)\")\n",
    "else:\n",
    "    print(f\"\\nShowing all {len(all_endpoints)} endpoints\")\n",
    "print(\"\\nCluster centers (in normalized coordinates):\")\n",
    "for i, center in enumerate(cluster_centers_original):\n",
    "    print(f\"  Cluster {i}: x={center[0]:6.2f}m, y={center[1]:6.2f}m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa420ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Cluster distribution bar chart\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "cluster_counts = [np.sum(cluster_labels == i) for i in range(N_CLUSTERS)]\n",
    "colors_bar = [plt.cm.tab10(i) for i in range(N_CLUSTERS)]\n",
    "\n",
    "ax.bar(range(N_CLUSTERS), cluster_counts, color=colors_bar, alpha=0.7, edgecolor='black')\n",
    "ax.set_xticks(range(N_CLUSTERS))\n",
    "ax.set_xticklabels([f'Cluster {i}' for i in range(N_CLUSTERS)])\n",
    "ax.set_xlabel('Cluster ID', fontsize=12)\n",
    "ax.set_ylabel('Sample Count', fontsize=12)\n",
    "ax.set_title('Sample Distribution Across Clusters', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add count labels on bars\n",
    "for i, count in enumerate(cluster_counts):\n",
    "    ax.text(i, count + max(cluster_counts)*0.01, str(count), \n",
    "            ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a522cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Visualize full trajectories for each cluster (OPTIMIZED for speed)\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "print(\"\\nVisualizing trajectories from pre-loaded data...\")\n",
    "print(\"ðŸ’¡ Using LineCollection for 10x faster rendering\")\n",
    "\n",
    "for cluster_id in range(N_CLUSTERS):\n",
    "    ax = axes[cluster_id]\n",
    "    \n",
    "    # Get trajectories for this cluster\n",
    "    cluster_mask = cluster_labels == cluster_id\n",
    "    cluster_trajectories = all_trajectories[cluster_mask]\n",
    "    \n",
    "    # Limit number of trajectories to plot\n",
    "    n_plot = min(50, len(cluster_trajectories))\n",
    "    \n",
    "    # Prepare line segments for LineCollection (MUCH faster than individual plot() calls)\n",
    "    segments = []\n",
    "    for trajectory in cluster_trajectories[:n_plot]:\n",
    "        # Downsample to every 3rd point: 60 -> 20 points\n",
    "        downsampled = trajectory[::3, :]\n",
    "        # Create segments: list of (x,y) points\n",
    "        segments.append(downsampled)\n",
    "    \n",
    "    # Create LineCollection - this draws ALL lines in one operation!\n",
    "    lc = LineCollection(segments, colors=plt.cm.tab10(cluster_id), \n",
    "                       alpha=0.3, linewidths=1)\n",
    "    ax.add_collection(lc)\n",
    "    \n",
    "    # Set plot limits based on data\n",
    "    all_points = np.vstack(segments)\n",
    "    ax.set_xlim(all_points[:, 0].min() - 5, all_points[:, 0].max() + 5)\n",
    "    ax.set_ylim(all_points[:, 1].min() - 5, all_points[:, 1].max() + 5)\n",
    "    \n",
    "    # Plot cluster center endpoint\n",
    "    center = cluster_centers_original[cluster_id]\n",
    "    ax.scatter(center[0], center[1], \n",
    "              marker='X', s=400, c=[plt.cm.tab10(cluster_id)],\n",
    "              edgecolors='black', linewidth=2, zorder=10)\n",
    "    \n",
    "    # Plot origin\n",
    "    ax.scatter(0, 0, marker='o', s=150, c='green',\n",
    "              edgecolors='black', linewidth=1.5, zorder=10)\n",
    "    \n",
    "    ax.set_xlabel('Normalized X (m)', fontsize=10)\n",
    "    ax.set_ylabel('Normalized Y (m)', fontsize=10)\n",
    "    ax.set_title(f'Cluster {cluster_id}\\n({np.sum(cluster_mask)} samples, showing {n_plot})', \n",
    "                fontsize=12, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"âœ… Trajectory visualization completed (optimized rendering)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d06e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Endpoint clustering statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ“Š Endpoint Clustering Statistics\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for cluster_id in range(N_CLUSTERS):\n",
    "    cluster_mask = cluster_labels == cluster_id\n",
    "    cluster_endpoints = all_endpoints[cluster_mask]\n",
    "    \n",
    "    center = cluster_centers_original[cluster_id]\n",
    "    mean_x = np.mean(cluster_endpoints[:, 0])\n",
    "    mean_y = np.mean(cluster_endpoints[:, 1])\n",
    "    std_x = np.std(cluster_endpoints[:, 0])\n",
    "    std_y = np.std(cluster_endpoints[:, 1])\n",
    "    \n",
    "    # Calculate distance from origin\n",
    "    distances = np.sqrt(cluster_endpoints[:, 0]**2 + cluster_endpoints[:, 1]**2)\n",
    "    mean_distance = np.mean(distances)\n",
    "    \n",
    "    # Calculate angle from y-axis (main direction)\n",
    "    angles = np.arctan2(cluster_endpoints[:, 0], cluster_endpoints[:, 1]) * 180 / np.pi\n",
    "    mean_angle = np.mean(angles)\n",
    "    \n",
    "    print(f\"\\nCluster {cluster_id}:\")\n",
    "    print(f\"  Count: {np.sum(cluster_mask)} samples\")\n",
    "    print(f\"  Center: ({center[0]:6.2f}, {center[1]:6.2f}) m\")\n",
    "    print(f\"  Mean endpoint: ({mean_x:6.2f}, {mean_y:6.2f}) m\")\n",
    "    print(f\"  Std X/Y: ({std_x:5.2f}, {std_y:5.2f}) m\")\n",
    "    print(f\"  Avg distance from origin: {mean_distance:6.2f} m\")\n",
    "    print(f\"  Avg angle from forward: {mean_angle:6.1f}Â°\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
