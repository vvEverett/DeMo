{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48b22ef3",
   "metadata": {},
   "source": [
    "# EGO Vehicle Trajectory Clustering\n",
    "\n",
    "Extract features from the last 6 seconds of EGO vehicle trajectories from the first 100 train files and perform clustering analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9012977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "project_root = Path.cwd().resolve()\n",
    "if not (project_root / \"src\").exists():\n",
    "    for parent in project_root.parents:\n",
    "        if (parent / \"src\").exists():\n",
    "            project_root = parent\n",
    "            break\n",
    "\n",
    "if (project_root / \"src\").exists() and str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from src.utils.data_visualization import get_available_files, DataLoader\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "print(\"✅ Libraries loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3b2ebf",
   "metadata": {},
   "source": [
    "## 1. Load data and extract EGO features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c46adbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_PATH = Path('/data1/xiaowei/code/DeMo/data/DeMo_processed')\n",
    "N_FILES = 1000\n",
    "TOTAL_TIMESTEPS = 110  # 11 seconds * 10 Hz\n",
    "HISTORY_TIMESTEPS = 50  # First 5 seconds\n",
    "FUTURE_TIMESTEPS = 60   # Last 6 seconds\n",
    "\n",
    "# Get files\n",
    "train_files = get_available_files(DATA_PATH, 'train')[:N_FILES]\n",
    "print(f\"📂 Loaded {len(train_files)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42935595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_trajectory(positions, velocity, angles):\n",
    "    \"\"\"\n",
    "    Normalize trajectory: start at origin, end aligned to y-axis\n",
    "    \n",
    "    Args:\n",
    "        positions: numpy array of shape (60, 2) - [x, y] positions\n",
    "        velocity: numpy array of shape (60,) - velocity values\n",
    "        angles: numpy array of shape (60,) - heading angles\n",
    "    \n",
    "    Returns:\n",
    "        features: numpy array of shape (60, 4) - [normalized_x, normalized_y, velocity, angle]\n",
    "    \"\"\"\n",
    "    # 1. Translation: Move start to origin\n",
    "    start_pos = positions[0]\n",
    "    end_pos = positions[-1]\n",
    "    positions_normalized = positions - start_pos  # (60, 2)\n",
    "    \n",
    "    # 2. Rotation alignment: Align start->end vector to positive y-axis direction\n",
    "    # Calculate vector from start to end\n",
    "    start_to_end = end_pos - start_pos\n",
    "    target_angle = np.arctan2(start_to_end[1], start_to_end[0])  # Current angle\n",
    "    \n",
    "    # Calculate rotation angle (rotate vector to positive y-axis, i.e., 90 degrees)\n",
    "    rotation_angle = np.pi / 2 - target_angle\n",
    "    \n",
    "    # Construct rotation matrix\n",
    "    cos_theta = np.cos(rotation_angle)\n",
    "    sin_theta = np.sin(rotation_angle)\n",
    "    rotation_matrix = np.array([\n",
    "        [cos_theta, -sin_theta],\n",
    "        [sin_theta, cos_theta]\n",
    "    ])\n",
    "    \n",
    "    # Apply rotation to positions\n",
    "    positions_aligned = positions_normalized @ rotation_matrix.T  # (60, 2)\n",
    "    \n",
    "    # Apply rotation to angles (adjust all angles by rotation_angle)\n",
    "    angles_aligned = angles - rotation_angle\n",
    "    \n",
    "    # 3. Feature combination: [normalized x, y, velocity, angle]\n",
    "    features = np.column_stack([\n",
    "        positions_aligned[:, 0],  # aligned x (lateral offset)\n",
    "        positions_aligned[:, 1],  # aligned y (longitudinal progress)\n",
    "        velocity,                 # original velocity\n",
    "        angles_aligned            # aligned heading angles\n",
    "    ])  # (60, 4)\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "def extract_ego_features(file_path):\n",
    "    \"\"\"\n",
    "    Extract features from the last 6 seconds of EGO vehicle trajectory using DataLoader\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the data file\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (features, agent_type_combined) where:\n",
    "            - features: numpy array of shape (60, 4) or None if invalid\n",
    "            - agent_type_combined: string indicating agent type ('Vehicle', 'Pedestrian', 'Cyclist', 'Other')\n",
    "    \"\"\"\n",
    "    # Use DataLoader to load and extract ego data\n",
    "    loader = DataLoader()\n",
    "    data = loader.load_scenario(file_path)\n",
    "    \n",
    "    if data is None:\n",
    "        return None, None\n",
    "    \n",
    "    # Get focal agent index\n",
    "    focal_idx = loader.current_metadata['focal_agent_idx']\n",
    "    \n",
    "    # Use plot_ego_velocity_analysis to get comprehensive ego data\n",
    "    # This includes positions, velocities, angles, and accelerations\n",
    "    from src.utils.data_visualization import plot_ego_velocity_analysis\n",
    "    \n",
    "    analysis_data = plot_ego_velocity_analysis(loader, show_acceleration=False, time_window=None)\n",
    "    \n",
    "    if analysis_data is None:\n",
    "        return None, None\n",
    "    \n",
    "    # Extract agent_type_combined\n",
    "    agent_type_combined = analysis_data['agent_type_combined']\n",
    "    \n",
    "    # Get full trajectory data\n",
    "    positions_full = analysis_data['positions']\n",
    "    velocities_full = analysis_data['velocities']\n",
    "    angles_full = analysis_data['angles']\n",
    "    timesteps_full = analysis_data['timesteps']\n",
    "    \n",
    "    # Filter for future timesteps (timestep 50-110, i.e., last 6 seconds)\n",
    "    future_mask = timesteps_full >= HISTORY_TIMESTEPS\n",
    "    \n",
    "    if not future_mask.any():\n",
    "        return None, None\n",
    "    \n",
    "    positions = positions_full[future_mask]\n",
    "    velocity = velocities_full[future_mask]\n",
    "    angles = angles_full[future_mask]\n",
    "    \n",
    "    # Check if we have exactly 60 timesteps\n",
    "    if len(positions) != FUTURE_TIMESTEPS:\n",
    "        return None, None\n",
    "    \n",
    "    # Normalize trajectory with positions, velocity, and angles from DataLoader\n",
    "    features = normalize_trajectory(positions, velocity, angles)\n",
    "    \n",
    "    return features, agent_type_combined\n",
    "\n",
    "\n",
    "# Extract all features and agent types\n",
    "all_features = []\n",
    "all_agent_types = []\n",
    "valid_files = []\n",
    "\n",
    "print(\"Extracting features using DataLoader with plot_ego_velocity_analysis...\")\n",
    "print(\"💡 This provides comprehensive data: positions, velocities, angles from the data loader\")\n",
    "for i, file_path in enumerate(train_files):\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print(f\"  Processing {i + 1}/{len(train_files)}...\")\n",
    "    \n",
    "    features, agent_type = extract_ego_features(file_path)\n",
    "    if features is not None:\n",
    "        all_features.append(features)\n",
    "        all_agent_types.append(agent_type)\n",
    "        valid_files.append(file_path.name)\n",
    "\n",
    "print(f\"\\n✅ Successfully extracted features from {len(all_features)} scenarios\")\n",
    "print(f\"Feature dimensions: {all_features[0].shape}\")\n",
    "print(f\"💡 Features include: [normalized_x, normalized_y, velocity, angle]\")\n",
    "print(f\"💡 All data sourced from DataLoader's get_agent_trajectory method\")\n",
    "\n",
    "# Show agent type distribution\n",
    "from collections import Counter\n",
    "agent_type_counts = Counter(all_agent_types)\n",
    "print(f\"\\n📊 Agent Type Distribution:\")\n",
    "for agent_type, count in sorted(agent_type_counts.items()):\n",
    "    print(f\"  {agent_type}: {count} ({count/len(all_agent_types)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb284b71",
   "metadata": {},
   "source": [
    "## 1.5 Heuristic Rule-Based Pre-Classification\n",
    "\n",
    "Apply heuristic rules to identify **Stop** and **Lane Keeping** scenarios before clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa365bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heuristic rule-based pre-classification with agent type support\n",
    "def classify_by_heuristics(features, agent_types):\n",
    "    \"\"\"\n",
    "    Classify trajectories using heuristic rules:\n",
    "    - Pedestrian: agent_type_combined == 'Pedestrian'\n",
    "    - Cyclist: agent_type_combined == 'Cyclist'\n",
    "    - Stop: velocity decreases and approaches 0\n",
    "    - Start from Stop: velocity starts near 0 and increases\n",
    "    - Lane Keeping: stable velocity with low variance\n",
    "    \n",
    "    Args:\n",
    "        features: array of shape (n_samples, 60, 4) containing [x, y, velocity, angle]\n",
    "        agent_types: list of agent_type_combined strings\n",
    "    \n",
    "    Returns:\n",
    "        labels: array of shape (n_samples,) with values:\n",
    "                -1 = Stop\n",
    "                -2 = Lane Keeping\n",
    "                -3 = Start from Stop\n",
    "                -4 = Other (needs clustering)\n",
    "                -5 = Pedestrian\n",
    "                -6 = Cyclist/Motorcyclist\n",
    "    \"\"\"\n",
    "    n_samples = len(features)\n",
    "    labels = np.full(n_samples, -4, dtype=int)  # Default: Other\n",
    "    \n",
    "    # Thresholds for classification\n",
    "    WINDOW_SIZE = 5  # Number of timesteps to average for initial/final speed\n",
    "    STOP_FINAL_SPEED_THRESHOLD = 2.0  # m/s, final speed close to 0\n",
    "    STOP_SPEED_DECREASE_THRESHOLD = -3.0  # m/s, significant speed decrease\n",
    "    START_INITIAL_SPEED_THRESHOLD = 2.0  # m/s, initial speed close to 0\n",
    "    START_SPEED_INCREASE_THRESHOLD = 3.0  # m/s, significant speed increase\n",
    "    LANE_KEEPING_SPEED_STD_THRESHOLD = 1.5  # m/s, low speed variance\n",
    "    LANE_KEEPING_ANGLE_STD_THRESHOLD = 0.15  # rad, low heading change (~8.6 degrees)\n",
    "    LANE_KEEPING_LATERAL_THRESHOLD = 2.0  # m, small lateral deviation\n",
    "    \n",
    "    for i, sample in enumerate(features):\n",
    "        agent_type = agent_types[i]\n",
    "        \n",
    "        # Rule 0: Agent type-based classification (highest priority)\n",
    "        if agent_type == 'Pedestrian':\n",
    "            labels[i] = -5  # Pedestrian\n",
    "            continue\n",
    "        elif agent_type == 'Cyclist':\n",
    "            labels[i] = -6  # Cyclist/Motorcyclist\n",
    "            continue\n",
    "        \n",
    "        # For vehicles, apply trajectory-based rules\n",
    "        velocities = sample[:, 2]\n",
    "        angles = sample[:, 3]\n",
    "        x_positions = sample[:, 0]\n",
    "        \n",
    "        # Calculate statistics\n",
    "        # Use average speed over first/last 5 timesteps for smoother detection\n",
    "        initial_speed = np.mean(velocities[:WINDOW_SIZE])  # Average of first 5 points\n",
    "        final_speed = np.mean(velocities[-WINDOW_SIZE:])   # Average of last 5 points\n",
    "        speed_change = final_speed - initial_speed\n",
    "        speed_std = np.std(velocities)\n",
    "        angle_std = np.std(angles)\n",
    "        lateral_deviation = np.std(x_positions)  # Lateral deviation from centerline\n",
    "        \n",
    "        # Rule 1: Stop - average final speed approaches 0 and speed decreases\n",
    "        if final_speed < STOP_FINAL_SPEED_THRESHOLD and speed_change < STOP_SPEED_DECREASE_THRESHOLD:\n",
    "            labels[i] = -1  # Stop\n",
    "        \n",
    "        # Rule 2: Start from Stop - average initial speed near 0 and speed increases\n",
    "        elif initial_speed < START_INITIAL_SPEED_THRESHOLD and speed_change > START_SPEED_INCREASE_THRESHOLD:\n",
    "            labels[i] = -3  # Start from Stop\n",
    "        \n",
    "        # Rule 3: Lane Keeping - stable speed, stable heading, small lateral deviation\n",
    "        elif (speed_std < LANE_KEEPING_SPEED_STD_THRESHOLD and \n",
    "              angle_std < LANE_KEEPING_ANGLE_STD_THRESHOLD and\n",
    "              lateral_deviation < LANE_KEEPING_LATERAL_THRESHOLD):\n",
    "            labels[i] = -2  # Lane Keeping\n",
    "        \n",
    "        # Otherwise: remains as -4 (Other - needs clustering)\n",
    "    \n",
    "    return labels\n",
    "\n",
    "# Apply heuristic classification with agent types\n",
    "heuristic_labels = classify_by_heuristics(all_features, all_agent_types)\n",
    "\n",
    "# Count samples in each category\n",
    "n_stop = np.sum(heuristic_labels == -1)\n",
    "n_lane_keeping = np.sum(heuristic_labels == -2)\n",
    "n_start = np.sum(heuristic_labels == -3)\n",
    "n_other = np.sum(heuristic_labels == -4)\n",
    "n_pedestrian = np.sum(heuristic_labels == -5)\n",
    "n_cyclist = np.sum(heuristic_labels == -6)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"🔍 Heuristic Rule-Based Pre-Classification Results:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  Pedestrian scenarios:      {n_pedestrian:3d} ({n_pedestrian/len(all_features)*100:5.1f}%)\")\n",
    "print(f\"  Cyclist scenarios:         {n_cyclist:3d} ({n_cyclist/len(all_features)*100:5.1f}%)\")\n",
    "print(f\"  Stop scenarios:            {n_stop:3d} ({n_stop/len(all_features)*100:5.1f}%)\")\n",
    "print(f\"  Lane Keeping scenarios:    {n_lane_keeping:3d} ({n_lane_keeping/len(all_features)*100:5.1f}%)\")\n",
    "print(f\"  Start from Stop scenarios: {n_start:3d} ({n_start/len(all_features)*100:5.1f}%)\")\n",
    "print(f\"  Other scenarios:           {n_other:3d} ({n_other/len(all_features)*100:5.1f}%)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n💡 {n_other} scenarios will proceed to DTW clustering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ce7dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLUSTER = 4\n",
    "# DTW clustering for \"Other\" scenarios only\n",
    "try:\n",
    "    from tslearn.clustering import TimeSeriesKMeans\n",
    "    from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "    \n",
    "    # Get indices of \"Other\" scenarios\n",
    "    other_indices = np.where(heuristic_labels == -4)[0]\n",
    "    other_features = [all_features[i] for i in other_indices]\n",
    "    \n",
    "    if len(other_features) > 0:\n",
    "        # Standardize time series data for \"Other\" scenarios\n",
    "        ts_scaler = TimeSeriesScalerMeanVariance()\n",
    "        X_ts_scaled = ts_scaler.fit_transform(other_features)\n",
    "\n",
    "        # Use DTW distance K-Means (4 clusters for remaining scenarios)\n",
    "        n_clusters_dtw = N_CLUSTER\n",
    "        ts_kmeans = TimeSeriesKMeans(n_clusters=n_clusters_dtw, metric=\"dtw\", random_state=42)\n",
    "        dtw_labels = ts_kmeans.fit_predict(X_ts_scaled)\n",
    "        \n",
    "        # Combine heuristic labels and DTW labels\n",
    "        # Final labels: -1 (Stop), -2 (Lane Keeping), -3 (Start from Stop), 0-5 (DTW clusters)\n",
    "        ts_labels = heuristic_labels.copy()\n",
    "        ts_labels[other_indices] = dtw_labels\n",
    "        \n",
    "        print(\"\\n✅ DTW time series clustering completed for 'Other' scenarios\")\n",
    "        print(f\"DTW clustering distribution: {np.bincount(dtw_labels)}\")\n",
    "        print(f\"\\n📊 Final Label Distribution:\")\n",
    "        print(f\"  Label -1 (Stop):            {np.sum(ts_labels == -1)} samples\")\n",
    "        print(f\"  Label -2 (Lane Keeping):    {np.sum(ts_labels == -2)} samples\")\n",
    "        print(f\"  Label -3 (Start from Stop): {np.sum(ts_labels == -3)} samples\")\n",
    "        for cluster_id in range(n_clusters_dtw):\n",
    "            print(f\"  Label {cluster_id}  (DTW Cluster):     {np.sum(ts_labels == cluster_id)} samples\")\n",
    "    else:\n",
    "        print(\"⚠️ No 'Other' scenarios to cluster - all samples classified by heuristics\")\n",
    "        ts_labels = heuristic_labels.copy()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"⚠️ tslearn not installed, skipping DTW clustering\")\n",
    "    print(\"   To use, run: pip install tslearn\")\n",
    "    ts_labels = heuristic_labels.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c32bfe",
   "metadata": {},
   "source": [
    "## 2. Visualize clustering results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5d97b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Cluster distribution statistics\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Get cluster counts including negative labels\n",
    "unique_labels = np.unique(ts_labels)\n",
    "label_names = []\n",
    "cluster_counts_list = []\n",
    "\n",
    "for label in sorted(unique_labels):\n",
    "    count = np.sum(ts_labels == label)\n",
    "    cluster_counts_list.append(count)\n",
    "    if label == -6:\n",
    "        label_names.append('Cyclist')\n",
    "    elif label == -5:\n",
    "        label_names.append('Pedestrian')\n",
    "    elif label == -3:\n",
    "        label_names.append('Start from Stop')\n",
    "    elif label == -2:\n",
    "        label_names.append('Lane Keeping')\n",
    "    elif label == -1:\n",
    "        label_names.append('Stop')\n",
    "    else:\n",
    "        label_names.append(f'Cluster {label}')\n",
    "\n",
    "# Plot cluster distribution bar chart\n",
    "colors_bar = ['#9B59B6' if l == -6 else '#3498DB' if l == -5 else '#FFB84D' if l == -3 \n",
    "              else '#4ECDC4' if l == -2 else '#FF6B6B' if l == -1 else 'steelblue' \n",
    "              for l in sorted(unique_labels)]\n",
    "axes[0].bar(range(len(cluster_counts_list)), cluster_counts_list, color=colors_bar, alpha=0.7)\n",
    "axes[0].set_xticks(range(len(cluster_counts_list)))\n",
    "axes[0].set_xticklabels(label_names, rotation=45, ha='right')\n",
    "axes[0].set_xlabel('Cluster ID', fontsize=12)\n",
    "axes[0].set_ylabel('Sample Count', fontsize=12)\n",
    "axes[0].set_title('Sample Distribution Across Clusters (with Heuristic Rules)', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot cluster distribution pie chart\n",
    "colors_pie = ['#9B59B6' if l == -6 else '#3498DB' if l == -5 else '#FFB84D' if l == -3 \n",
    "              else '#4ECDC4' if l == -2 else '#FF6B6B' if l == -1 else plt.cm.Set3(i) \n",
    "              for i, l in enumerate(sorted(unique_labels))]\n",
    "axes[1].pie(cluster_counts_list, labels=label_names,\n",
    "            autopct='%1.1f%%', colors=colors_pie, startangle=90)\n",
    "axes[1].set_title('Cluster Sample Proportions', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n📊 Cluster Distribution Details:\")\n",
    "for label, name, count in zip(sorted(unique_labels), label_names, cluster_counts_list):\n",
    "    print(f\"  {name:20s}: {count} samples ({count/len(ts_labels)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa420ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Typical trajectory visualization for each cluster\n",
    "unique_labels = sorted(np.unique(ts_labels))\n",
    "n_clusters = len(unique_labels)\n",
    "\n",
    "# Create 2x5 layout for up to 10 clusters\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Get cluster counts\n",
    "cluster_counts = {label: np.sum(ts_labels == label) for label in unique_labels}\n",
    "\n",
    "for idx, cluster_id in enumerate(unique_labels):\n",
    "    if idx >= 10:  # Only show first 10 clusters\n",
    "        break\n",
    "    \n",
    "    # Get all samples for this cluster\n",
    "    cluster_mask = ts_labels == cluster_id\n",
    "    cluster_samples = [all_features[i] for i in range(len(all_features)) if cluster_mask[i]]\n",
    "    \n",
    "    # Plot all trajectories for this cluster (relative to start position)\n",
    "    ax = axes[idx]\n",
    "    for sample in cluster_samples:\n",
    "        # Convert to relative positions\n",
    "        x_rel = sample[:, 0] - sample[0, 0]\n",
    "        y_rel = sample[:, 1] - sample[0, 1]\n",
    "        ax.plot(x_rel, y_rel, alpha=0.3, linewidth=1)\n",
    "    \n",
    "    # Calculate and plot average trajectory (relative)\n",
    "    mean_sample = np.mean(cluster_samples, axis=0)\n",
    "    mean_x_rel = mean_sample[:, 0] - mean_sample[0, 0]\n",
    "    mean_y_rel = mean_sample[:, 1] - mean_sample[0, 1]\n",
    "    ax.plot(mean_x_rel, mean_y_rel, color='red', linewidth=3, label='Average Trajectory')\n",
    "    \n",
    "    ax.scatter(0, 0, color='green', s=100, marker='o', label='Start Point', zorder=5)\n",
    "    ax.scatter(mean_x_rel[-1], mean_y_rel[-1], color='red', s=100, marker='*', label='End Point', zorder=5)\n",
    "    \n",
    "    # Set title with cluster name\n",
    "    if cluster_id == -6:\n",
    "        title_name = 'Cyclist'\n",
    "        ax.set_facecolor('#F0E5F5')\n",
    "    elif cluster_id == -5:\n",
    "        title_name = 'Pedestrian'\n",
    "        ax.set_facecolor('#E5EFF5')\n",
    "    elif cluster_id == -3:\n",
    "        title_name = 'Start from Stop'\n",
    "        ax.set_facecolor('#FFF3E5')\n",
    "    elif cluster_id == -2:\n",
    "        title_name = 'Lane Keeping'\n",
    "        ax.set_facecolor('#E5F5F4')\n",
    "    elif cluster_id == -1:\n",
    "        title_name = 'Stop'\n",
    "        ax.set_facecolor('#FFE5E5')\n",
    "    else:\n",
    "        title_name = f'Cluster {cluster_id}'\n",
    "    \n",
    "    ax.set_xlabel('Relative X Position (m)', fontsize=10)\n",
    "    ax.set_ylabel('Relative Y Position (m)', fontsize=10)\n",
    "    ax.set_title(f'{title_name}\\n({cluster_counts[cluster_id]} samples)', fontsize=12, fontweight='bold')\n",
    "    ax.legend(loc='best', fontsize=8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.axis('equal')\n",
    "\n",
    "# Hide unused subplots\n",
    "for idx in range(n_clusters, 10):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a522cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Speed pattern visualization\n",
    "unique_labels = sorted(np.unique(ts_labels))\n",
    "n_clusters = len(unique_labels)\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "cluster_counts = {label: np.sum(ts_labels == label) for label in unique_labels}\n",
    "\n",
    "for idx, cluster_id in enumerate(unique_labels):\n",
    "    if idx >= 10:  # Only show first 10 clusters\n",
    "        break\n",
    "    \n",
    "    cluster_mask = ts_labels == cluster_id\n",
    "    cluster_samples = [all_features[i] for i in range(len(all_features)) if cluster_mask[i]]\n",
    "    \n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Plot velocity for all samples\n",
    "    for sample in cluster_samples:\n",
    "        vel = sample[:, 2]\n",
    "        ax.plot(vel, alpha=0.2, linewidth=1, color='blue')\n",
    "    \n",
    "    # Plot average velocity\n",
    "    mean_vel = np.mean([s[:, 2] for s in cluster_samples], axis=0)\n",
    "    ax.plot(mean_vel, color='red', linewidth=2.5, label='Average')\n",
    "    \n",
    "    ax.axhline(y=0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "    \n",
    "    # Set title with cluster name and background color\n",
    "    if cluster_id == -6:\n",
    "        title_name = 'Cyclist'\n",
    "        ax.set_facecolor('#F0E5F5')\n",
    "    elif cluster_id == -5:\n",
    "        title_name = 'Pedestrian'\n",
    "        ax.set_facecolor('#E5EFF5')\n",
    "    elif cluster_id == -3:\n",
    "        title_name = 'Start from Stop'\n",
    "        ax.set_facecolor('#FFF3E5')\n",
    "    elif cluster_id == -2:\n",
    "        title_name = 'Lane Keeping'\n",
    "        ax.set_facecolor('#E5F5F4')\n",
    "    elif cluster_id == -1:\n",
    "        title_name = 'Stop'\n",
    "        ax.set_facecolor('#FFE5E5')\n",
    "    else:\n",
    "        title_name = f'Cluster {cluster_id}'\n",
    "    \n",
    "    ax.set_xlabel('Time Step', fontsize=10)\n",
    "    ax.set_ylabel('Velocity (m/s)', fontsize=10)\n",
    "    ax.set_title(f'{title_name} Speed Pattern', fontsize=12, fontweight='bold')\n",
    "    ax.legend(loc='best', fontsize=8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Hide unused subplots\n",
    "for idx in range(n_clusters, 10):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a85d661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Cluster feature statistics comparison\n",
    "unique_labels = sorted(np.unique(ts_labels))\n",
    "cluster_stats = []\n",
    "\n",
    "for cluster_id in unique_labels:\n",
    "    cluster_mask = ts_labels == cluster_id\n",
    "    cluster_samples = [all_features[i] for i in range(len(all_features)) if cluster_mask[i]]\n",
    "    \n",
    "    # Calculate statistics\n",
    "    all_samples_array = np.array(cluster_samples)  # (n_samples, 60, 4)\n",
    "    \n",
    "    # Cluster name\n",
    "    if cluster_id == -6:\n",
    "        cluster_name = 'Cyclist'\n",
    "    elif cluster_id == -5:\n",
    "        cluster_name = 'Pedestrian'\n",
    "    elif cluster_id == -3:\n",
    "        cluster_name = 'Start from Stop'\n",
    "    elif cluster_id == -2:\n",
    "        cluster_name = 'Lane Keeping'\n",
    "    elif cluster_id == -1:\n",
    "        cluster_name = 'Stop'\n",
    "    else:\n",
    "        cluster_name = f'Cluster {cluster_id}'\n",
    "    \n",
    "    stats = {\n",
    "        'cluster': cluster_name,\n",
    "        'label': cluster_id,\n",
    "        'count': len(cluster_samples),\n",
    "        'avg_x_displacement': np.mean([s[-1, 0] - s[0, 0] for s in cluster_samples]),  # Final - initial X\n",
    "        'avg_y_displacement': np.mean([s[-1, 1] - s[0, 1] for s in cluster_samples]),  # Final - initial Y\n",
    "        'avg_total_displacement': np.mean([np.sqrt((s[-1, 0] - s[0, 0])**2 + (s[-1, 1] - s[0, 1])**2) for s in cluster_samples]),\n",
    "        'avg_speed_change': np.mean([np.sum(np.diff(s[:, 2])) for s in cluster_samples]),  # Total speed change\n",
    "        'speed_volatility': np.mean([np.std(s[:, 2]) for s in cluster_samples])\n",
    "    }\n",
    "    cluster_stats.append(stats)\n",
    "\n",
    "# Convert to DataFrame and display\n",
    "import pandas as pd\n",
    "stats_df = pd.DataFrame(cluster_stats)\n",
    "stats_df = stats_df.round(3)\n",
    "\n",
    "print(\"\\n📈 Statistical Feature Comparison Across Clusters:\\n\")\n",
    "print(stats_df[['cluster', 'count', 'avg_x_displacement', 'avg_y_displacement', \n",
    "                'avg_total_displacement', 'avg_speed_change', 'speed_volatility']].to_string(index=False))\n",
    "\n",
    "# Visualize statistical features\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "# Prepare colors\n",
    "bar_colors = ['#9B59B6' if label == -6 else '#3498DB' if label == -5 else '#FFB84D' if label == -3 \n",
    "              else '#4ECDC4' if label == -2 else '#FF6B6B' if label == -1 else 'steelblue' \n",
    "              for label in stats_df['label']]\n",
    "\n",
    "# Average X Displacement\n",
    "axes[0, 0].bar(range(len(stats_df)), stats_df['avg_x_displacement'], color=bar_colors)\n",
    "axes[0, 0].set_xticks(range(len(stats_df)))\n",
    "axes[0, 0].set_xticklabels(stats_df['cluster'], rotation=45, ha='right', fontsize=8)\n",
    "axes[0, 0].set_ylabel('Average X Displacement (m)')\n",
    "axes[0, 0].set_title('Average X Displacement Comparison')\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Average Y Displacement\n",
    "axes[0, 1].bar(range(len(stats_df)), stats_df['avg_y_displacement'], color=bar_colors)\n",
    "axes[0, 1].set_xticks(range(len(stats_df)))\n",
    "axes[0, 1].set_xticklabels(stats_df['cluster'], rotation=45, ha='right', fontsize=8)\n",
    "axes[0, 1].set_ylabel('Average Y Displacement (m)')\n",
    "axes[0, 1].set_title('Average Y Displacement Comparison')\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Total Displacement\n",
    "axes[0, 2].bar(range(len(stats_df)), stats_df['avg_total_displacement'], color=bar_colors)\n",
    "axes[0, 2].set_xticks(range(len(stats_df)))\n",
    "axes[0, 2].set_xticklabels(stats_df['cluster'], rotation=45, ha='right', fontsize=8)\n",
    "axes[0, 2].set_ylabel('Average Total Displacement (m)')\n",
    "axes[0, 2].set_title('Total Displacement Comparison')\n",
    "axes[0, 2].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Speed Change\n",
    "axes[0, 3].bar(range(len(stats_df)), stats_df['avg_speed_change'], color=bar_colors)\n",
    "axes[0, 3].set_xticks(range(len(stats_df)))\n",
    "axes[0, 3].set_xticklabels(stats_df['cluster'], rotation=45, ha='right', fontsize=8)\n",
    "axes[0, 3].set_ylabel('Average Speed Change (m/s)')\n",
    "axes[0, 3].set_title('Average Speed Change Comparison')\n",
    "axes[0, 3].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Speed Volatility\n",
    "axes[1, 0].bar(range(len(stats_df)), stats_df['speed_volatility'], color=bar_colors)\n",
    "axes[1, 0].set_xticks(range(len(stats_df)))\n",
    "axes[1, 0].set_xticklabels(stats_df['cluster'], rotation=45, ha='right', fontsize=8)\n",
    "axes[1, 0].set_ylabel('Speed Volatility (m/s)')\n",
    "axes[1, 0].set_title('Speed Volatility Comparison')\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Average Speed\n",
    "avg_speed = [np.mean([s[:, 2] for s in cluster_samples]) for cluster_samples in \n",
    "             [[all_features[i] for i in range(len(all_features)) if ts_labels[i] == label] \n",
    "              for label in unique_labels]]\n",
    "axes[1, 1].bar(range(len(stats_df)), avg_speed, color=bar_colors)\n",
    "axes[1, 1].set_xticks(range(len(stats_df)))\n",
    "axes[1, 1].set_xticklabels(stats_df['cluster'], rotation=45, ha='right', fontsize=8)\n",
    "axes[1, 1].set_ylabel('Average Speed (m/s)')\n",
    "axes[1, 1].set_title('Average Speed Comparison')\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Max Speed\n",
    "max_speed = [np.max([np.max(s[:, 2]) for s in cluster_samples]) for cluster_samples in \n",
    "             [[all_features[i] for i in range(len(all_features)) if ts_labels[i] == label] \n",
    "              for label in unique_labels]]\n",
    "axes[1, 2].bar(range(len(stats_df)), max_speed, color=bar_colors)\n",
    "axes[1, 2].set_xticks(range(len(stats_df)))\n",
    "axes[1, 2].set_xticklabels(stats_df['cluster'], rotation=45, ha='right', fontsize=8)\n",
    "axes[1, 2].set_ylabel('Max Speed (m/s)')\n",
    "axes[1, 2].set_title('Max Speed Comparison')\n",
    "axes[1, 2].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Angle Volatility\n",
    "angle_volatility = [np.mean([np.std(s[:, 3]) for s in cluster_samples]) for cluster_samples in \n",
    "                    [[all_features[i] for i in range(len(all_features)) if ts_labels[i] == label] \n",
    "                     for label in unique_labels]]\n",
    "axes[1, 3].bar(range(len(stats_df)), angle_volatility, color=bar_colors)\n",
    "axes[1, 3].set_xticks(range(len(stats_df)))\n",
    "axes[1, 3].set_xticklabels(stats_df['cluster'], rotation=45, ha='right', fontsize=8)\n",
    "axes[1, 3].set_ylabel('Angle Volatility (rad)')\n",
    "axes[1, 3].set_title('Angle Volatility Comparison')\n",
    "axes[1, 3].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d06e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Use t-SNE for dimensionality reduction visualization\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Flatten time series data for t-SNE\n",
    "X_flat = np.array([feat.flatten() for feat in all_features])\n",
    "\n",
    "# t-SNE reduce to 2D\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "X_tsne = tsne.fit_transform(X_flat)\n",
    "\n",
    "# Visualization with different colors for all categories\n",
    "unique_labels = sorted(np.unique(ts_labels))\n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "\n",
    "# Create color map\n",
    "color_map = []\n",
    "for label in ts_labels:\n",
    "    if label == -6:\n",
    "        color_map.append('#9B59B6')  # Purple for Cyclist\n",
    "    elif label == -5:\n",
    "        color_map.append('#3498DB')  # Blue for Pedestrian\n",
    "    elif label == -3:\n",
    "        color_map.append('#FFB84D')  # Orange for Start from Stop\n",
    "    elif label == -2:\n",
    "        color_map.append('#4ECDC4')  # Teal for Lane Keeping\n",
    "    elif label == -1:\n",
    "        color_map.append('#FF6B6B')  # Red for Stop\n",
    "    else:\n",
    "        color_map.append(plt.cm.tab10(label % 10))  # Different colors for DTW clusters\n",
    "\n",
    "scatter = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=color_map, \n",
    "                      s=100, alpha=0.7, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "# Add cluster center annotations\n",
    "for cluster_id in unique_labels:\n",
    "    cluster_mask = ts_labels == cluster_id\n",
    "    cluster_center = X_tsne[cluster_mask].mean(axis=0)\n",
    "    \n",
    "    if cluster_id == -6:\n",
    "        marker_color = '#9B59B6'\n",
    "        label_text = 'Cyclist'\n",
    "    elif cluster_id == -5:\n",
    "        marker_color = '#3498DB'\n",
    "        label_text = 'Pedestrian'\n",
    "    elif cluster_id == -3:\n",
    "        marker_color = '#FFB84D'\n",
    "        label_text = 'Start'\n",
    "    elif cluster_id == -2:\n",
    "        marker_color = '#4ECDC4'\n",
    "        label_text = 'Lane Keep'\n",
    "    elif cluster_id == -1:\n",
    "        marker_color = '#FF6B6B'\n",
    "        label_text = 'Stop'\n",
    "    else:\n",
    "        marker_color = 'red'\n",
    "        label_text = f'C{cluster_id}'\n",
    "    \n",
    "    plt.scatter(cluster_center[0], cluster_center[1], \n",
    "                marker='X', s=500, c=marker_color, edgecolors='black', linewidth=2)\n",
    "    plt.text(cluster_center[0], cluster_center[1], label_text, \n",
    "             fontsize=12, fontweight='bold', ha='center', va='center',\n",
    "             bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "\n",
    "# Create custom legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='#9B59B6', edgecolor='black', label='Cyclist (Heuristic)'),\n",
    "    Patch(facecolor='#3498DB', edgecolor='black', label='Pedestrian (Heuristic)'),\n",
    "    Patch(facecolor='#FFB84D', edgecolor='black', label='Start from Stop (Heuristic)'),\n",
    "    Patch(facecolor='#4ECDC4', edgecolor='black', label='Lane Keeping (Heuristic)'),\n",
    "    Patch(facecolor='#FF6B6B', edgecolor='black', label='Stop (Heuristic)'),\n",
    "    Patch(facecolor='steelblue', edgecolor='black', label='DTW Clusters')\n",
    "]\n",
    "plt.legend(handles=legend_elements, loc='best', fontsize=11)\n",
    "\n",
    "plt.xlabel('t-SNE Dimension 1', fontsize=12)\n",
    "plt.ylabel('t-SNE Dimension 2', fontsize=12)\n",
    "plt.title('Trajectory Feature t-SNE Visualization\\n(Heuristic Rules + Agent Types + DTW Clustering)', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ t-SNE visualization completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeMo_XW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
